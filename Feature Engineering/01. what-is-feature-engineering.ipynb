{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5a23c6",
   "metadata": {
    "papermill": {
     "duration": 0.004041,
     "end_time": "2023-04-20T18:11:17.289495",
     "exception": false,
     "start_time": "2023-04-20T18:11:17.285454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Welcome to Feature Engineering! #\n",
    "\n",
    "In this course you'll learn about one of the most important steps on the way to building a great machine learning model: *feature engineering*. You'll learn how to:\n",
    "- determine which features are the most important with *mutual information*\n",
    "- invent(измислям, изнамирам, създавам) new features in several real-world problem domains\n",
    "- encode high-cardinality categoricals with a *target encoding*\n",
    "- create segmentation features with *k-means clustering*\n",
    "- decompose(разлагам) a dataset's variation into features with *principal component analysis*\n",
    "\n",
    "The hands-on exercises build up to a complete **[notebook](http://www.kaggle.com/ryanholbrook/feature-engineering-for-house-prices)** that applies all of these techniques to make a submission to the **[House Prices Getting Started](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)** competition. After completing this course, you'll have several ideas that you can use to further improve your performance.\n",
    "\n",
    "Are you ready? Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3160190",
   "metadata": {
    "papermill": {
     "duration": 0.002588,
     "end_time": "2023-04-20T18:11:17.295278",
     "exception": false,
     "start_time": "2023-04-20T18:11:17.292690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The Goal of Feature Engineering #\n",
    " *(Цел на инженерството на характеристиките)*\n",
    "\n",
    "The goal of feature engineering is simply to make your data better suited to the problem at hand(конкретния проблем).\n",
    "\n",
    "Consider \"apparent temperature\" measures like the heat index and the wind chill. These quantities attempt to measure the *perceived* temperature to humans based on air temperature, humidity, and wind speed, things which we can measure directly. You could think of an apparent temperature as the result of a kind of feature engineering, an attempt to make the observed data more relevant to what we actually care about: how it actually feels outside!\n",
    "\n",
    "*Помислете за мерки за „видима температура“ като топлинен индекс и студен вятър. Тези количества се опитват да измерят **_възприеманата_** температура от хората въз основа на температурата на въздуха, влажността и скоростта на вятъра, неща, които можем да измерим директно. Бихте могли да мислите за видима температура като за резултат от вид инженерство на характеристики, опит да направим наблюдаваните данни по-подходящи за това, което всъщност ни интересува: как всъщност се чувстваш навън!*\n",
    "\n",
    "You might perform feature engineering to:\n",
    "- improve a model's predictive performance\n",
    "- reduce computational or data needs\n",
    "- improve interpretability of the results\n",
    "\n",
    "# A Guiding Principle of Feature Engineering #\n",
    "*(Основен принцип в инженерството на характеристиките)*\n",
    "\n",
    "For a feature to be useful, it must have a relationship to the target that your model is able to learn. \n",
    "\n",
    "*За да бъде полезна дадена характеристикa, тя трябва да има връзка с целта, която вашият модел може да научи.*\n",
    "\n",
    "Linear models, for instance, are only able to learn linear relationships. So, when using a linear model, your goal is to transform the features to make their relationship to the target linear.\n",
    "\n",
    "The key idea here is that a transformation you apply to a feature becomes in essence a part of the model itself. Say you were trying to predict the `Price` of square plots of land from the `Length` of one side. Fitting a linear model directly to `Length` gives poor results: the relationship is not linear.\n",
    "\n",
    "*Ключовата идея тук е, че трансформацията, която прилагате към характеристиката, по същество става част от самия модел. Да кажем, че се опитвате да предвидите „цената“ на квадратни парцели земя от „дължината“ на едната страна. Напасването на линеен модел директно към „Дължина“ дава лоши резултати: връзката не е линейна.*\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/5D1z24N.png\" width=300, alt=\"A scatterplot of Length along the x-axis and Price along the y-axis, the points increasing in a curve, with a poorly-fitting line superimposed.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>A linear model fits poorly with only Length as feature.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "If we square the `Length` feature to get `'Area'`, however, we create a linear relationship. Adding `Area` to the feature set means this linear model can now fit a parabola. Squaring a feature, in other words, gave the linear model the ability to fit squared features.\n",
    "\n",
    "*Ако поставим на квадрат характеристиката „Дължина“, за да получим „Площ“, обаче, създаваме линейна връзка. Добавянето на „Площ“ към набора от характеристики означава, че този линеен модел вече може да се побере в парабола. С други думи, поставянето в квадрат на характеристика дава на линейния модел способността да напасва квадратни характеристики.*\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/BLRsYOK.png\" width=600, alt=\"Left: Area now on the x-axis. The points increasing in a linear shape, with a well-fitting line superimposed. Right: Length on the x-axis now. The points increase in a curve as before, and a well-fitting curve is superimposed.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center><strong>Left:</strong> The fit to Area is much better. <strong>Right:</strong> Which makes the fit to Length better as well.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "This should show you why there can be such a high return on time invested in feature engineering. Whatever relationships your model can't learn, you can provide yourself through transformations. As you develop your feature set, think about what information your model could use to achieve its best performance.\n",
    "\n",
    "*Това трябва да ви покаже, защо може да има толкова висока възвръщаемост на времето, инвестирано в инженеринг на характеристики. Каквито и взаимоотношения вашият модел да не може да научи, можете да си осигурите чрез трансформации. Докато разработвате своя набор от характеристики, помислете каква информация може да използва вашият модел, за да постигне най-доброто си представяне.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9ba5e",
   "metadata": {
    "papermill": {
     "duration": 0.002595,
     "end_time": "2023-04-20T18:11:17.300760",
     "exception": false,
     "start_time": "2023-04-20T18:11:17.298165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Example - Concrete Formulations #\n",
    "\n",
    "To illustrate these ideas we'll see how adding a few synthetic features to a dataset can improve the predictive performance of a random forest model.\n",
    "\n",
    "The [*Concrete*](https://www.kaggle.com/sinamhd9/concrete-comprehensive-strength) dataset contains a variety of concrete formulations and the resulting product's *compressive strength*, which is a measure of how much load that kind of concrete can bear. The task for this dataset is to predict a concrete's compressive strength given its formulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18cd7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>BlastFurnaceSlag</th>\n",
       "      <th>FlyAsh</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>CoarseAggregate</th>\n",
       "      <th>FineAggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>CompressiveStrength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement  BlastFurnaceSlag  FlyAsh  Water  Superplasticizer  \\\n",
       "0      540.0               0.0     0.0  162.0               2.5   \n",
       "1      540.0               0.0     0.0  162.0               2.5   \n",
       "2      332.5             142.5     0.0  228.0               0.0   \n",
       "3      332.5             142.5     0.0  228.0               0.0   \n",
       "4      198.6             132.4     0.0  192.0               0.0   \n",
       "...      ...               ...     ...    ...               ...   \n",
       "1025   276.4             116.0    90.3  179.6               8.9   \n",
       "1026   322.2               0.0   115.6  196.0              10.4   \n",
       "1027   148.5             139.4   108.6  192.7               6.1   \n",
       "1028   159.1             186.7     0.0  175.6              11.3   \n",
       "1029   260.9             100.5    78.3  200.6               8.6   \n",
       "\n",
       "      CoarseAggregate  FineAggregate  Age  CompressiveStrength  \n",
       "0              1040.0          676.0   28                79.99  \n",
       "1              1055.0          676.0   28                61.89  \n",
       "2               932.0          594.0  270                40.27  \n",
       "3               932.0          594.0  365                41.05  \n",
       "4               978.4          825.5  360                44.30  \n",
       "...               ...            ...  ...                  ...  \n",
       "1025            870.1          768.3   28                44.28  \n",
       "1026            817.9          813.4   28                31.18  \n",
       "1027            892.4          780.0   28                23.70  \n",
       "1028            989.6          788.9   28                32.77  \n",
       "1029            864.5          761.5   28                32.40  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\dobromir\\kaggle\\Feature Engineering\\datasets\\concrete.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cc387",
   "metadata": {
    "papermill": {
     "duration": 0.003007,
     "end_time": "2023-04-20T18:11:19.027514",
     "exception": false,
     "start_time": "2023-04-20T18:11:19.024507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can see here the various ingredients going into each variety of concrete. We'll see in a moment how adding some additional synthetic features derived from these can help a model to learn important relationships among them.\n",
    "\n",
    "We'll first establish a baseline by training the model on the un-augmented dataset. This will help us determine whether our new features are actually useful.\n",
    "\n",
    "Establishing baselines like this is good practice at the start of the feature engineering process. A baseline score can help you decide whether your new features are worth keeping, or whether you should discard them and possibly try something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57dcb483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:11:19.036719Z",
     "iopub.status.busy": "2023-04-20T18:11:19.035557Z",
     "iopub.status.idle": "2023-04-20T18:11:29.791647Z",
     "shell.execute_reply": "2023-04-20T18:11:29.790005Z"
    },
    "papermill": {
     "duration": 10.763752,
     "end_time": "2023-04-20T18:11:29.794561",
     "exception": false,
     "start_time": "2023-04-20T18:11:19.030809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Baseline Score: 8.232\n"
     ]
    }
   ],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(\"CompressiveStrength\")\n",
    "\n",
    "# Train and score baseline model\n",
    "baseline = RandomForestRegressor(criterion=\"absolute_error\", random_state=0)\n",
    "baseline_score = cross_val_score(\n",
    "    baseline, X, y, cv=5, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "baseline_score = -1 * baseline_score.mean()\n",
    "\n",
    "print(f\"MAE Baseline Score: {baseline_score:.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e7685c",
   "metadata": {
    "papermill": {
     "duration": 0.003214,
     "end_time": "2023-04-20T18:11:29.801310",
     "exception": false,
     "start_time": "2023-04-20T18:11:29.798096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you ever cook at home, you might know that the *ratio* of ingredients in a recipe is usually a better predictor of how the recipe turns out than their absolute amounts. We might reason then that ratios of the features above would be a good predictor of `CompressiveStrength`.\n",
    "\n",
    "The cell below adds three new ratio features to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdef1d82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:11:29.810131Z",
     "iopub.status.busy": "2023-04-20T18:11:29.809706Z",
     "iopub.status.idle": "2023-04-20T18:11:44.577916Z",
     "shell.execute_reply": "2023-04-20T18:11:44.576533Z"
    },
    "papermill": {
     "duration": 14.775831,
     "end_time": "2023-04-20T18:11:44.580577",
     "exception": false,
     "start_time": "2023-04-20T18:11:29.804746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Score with Ratio Features: 7.948\n"
     ]
    }
   ],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(\"CompressiveStrength\")\n",
    "\n",
    "# Create synthetic features\n",
    "X[\"FCRatio\"] = X[\"FineAggregate\"] / X[\"CoarseAggregate\"] # Coarse Aggregate -> едри инертни материали\n",
    "X[\"AggCmtRatio\"] = (X[\"CoarseAggregate\"] + X[\"FineAggregate\"]) / X[\"Cement\"]\n",
    "X[\"WtrCmtRatio\"] = X[\"Water\"] / X[\"Cement\"]\n",
    "\n",
    "# Train and score model on dataset with additional ratio features\n",
    "model = RandomForestRegressor(criterion=\"absolute_error\", random_state=0)\n",
    "score = cross_val_score(\n",
    "    model, X, y, cv=5, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "score = -1 * score.mean()\n",
    "\n",
    "print(f\"MAE Score with Ratio Features: {score:.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a79c9e7",
   "metadata": {
    "papermill": {
     "duration": 0.003308,
     "end_time": "2023-04-20T18:11:44.587957",
     "exception": false,
     "start_time": "2023-04-20T18:11:44.584649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And sure enough, performance improved! This is evidence that these new ratio features exposed important information to the model that it wasn't detecting before.\n",
    "\n",
    "# Continue #\n",
    "\n",
    "We've seen that engineering new features can improve model performance.  But how do you identify features in the dataset that might be useful to combine?  [**Discover useful features**](https://www.kaggle.com/ryanholbrook/mutual-information) with mutual information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e665720c",
   "metadata": {
    "papermill": {
     "duration": 0.003321,
     "end_time": "2023-04-20T18:11:44.594922",
     "exception": false,
     "start_time": "2023-04-20T18:11:44.591601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/feature-engineering/discussion) to chat with other learners.*"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39.806849,
   "end_time": "2023-04-20T18:11:45.423057",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-20T18:11:05.616208",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
